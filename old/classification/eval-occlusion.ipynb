{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import timm\n",
    "import time\n",
    "\n",
    "from face_alignment.detection.blazeface import blazeface_detector\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    ViTForImageClassification, \n",
    "    ResNetForImageClassification,\n",
    "    ViTImageProcessor, \n",
    "    ConvNextImageProcessor, \n",
    "    PreTrainedModel, \n",
    "    PretrainedConfig)\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VggConfig(PretrainedConfig):\n",
    "    model_type = \"vgg16\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class myvgg16(PreTrainedModel):\n",
    "    config_class = VggConfig\n",
    "\n",
    "    def __init__(self, model, config):\n",
    "        super().__init__(config)\n",
    "        self.model = model\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        logits = self.model(pixel_values)\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}\n",
    "    \n",
    "class InceptionConfig(PretrainedConfig):\n",
    "    model_type = \"Inception V3\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class myinceptionv3(PreTrainedModel):\n",
    "    config_class = InceptionConfig\n",
    "\n",
    "    def __init__(self, model, config):\n",
    "        super().__init__(config)\n",
    "        self.model = model\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        logits = self.model(pixel_values)\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = Data (Images + Face masks)\n",
    "IMAGES_PATH = Path(r'D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images')\n",
    "MASKS_PATH = Path(r'D:\\ComputerScience\\Mestrado\\results\\Occlusion\\sam')\n",
    "\n",
    "# = Trained models\n",
    "VIT_PATH = Path(r'D:\\ComputerScience\\Mestrado\\results\\classification_models\\ViT')\n",
    "RESNET_PATH = Path(r'D:\\ComputerScience\\Mestrado\\results\\classification_models\\Resnet50')\n",
    "VGG_PATH = Path(r'D:\\ComputerScience\\Mestrado\\results\\classification_models\\Vgg16')\n",
    "INCEPTION_PATH = Path(r'D:\\ComputerScience\\Mestrado\\results\\classification_models\\InceptionV3')\n",
    "\n",
    "# = Mapping variables\n",
    "ID2LABEL = {0: 'com_dor', 1: 'sem_dor'}\n",
    "gt = {\n",
    "    'f1': 'com_dor',\n",
    "    'f2': 'sem_dor',\n",
    "    'f3': 'com_dor',\n",
    "    'f4': 'com_dor',\n",
    "    'f5': 'com_dor',\n",
    "    'f6': 'sem_dor',\n",
    "    'f7': 'com_dor',\n",
    "    'f8': 'sem_dor',\n",
    "    'f9': 'sem_dor',\n",
    "    'f10': 'sem_dor',\n",
    "}\n",
    "\n",
    "# = Image paths\n",
    "img_files = sorted(list(IMAGES_PATH.glob('*')), key=lambda a: int(a.stem[1:]))[:-1]\n",
    "\n",
    "# = Output\n",
    "accuracies = cols = {'ViT': [], 'Resnet50': [], 'Vgg16': [], 'InceptionV3': []}\n",
    "accuracies_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vit(training_set_name:str) -> Tuple[ViTForImageClassification,ViTImageProcessor]:\n",
    "    model_path = VIT_PATH / training_set_name\n",
    "    model = ViTForImageClassification.from_pretrained(model_path)\n",
    "    processor = ViTImageProcessor.from_pretrained(model_path)\n",
    "    return model, processor\n",
    "\n",
    "def load_resnet(training_set_name:str) -> Tuple[ResNetForImageClassification]:\n",
    "    model_path = RESNET_PATH / training_set_name\n",
    "    model = ResNetForImageClassification.from_pretrained(model_path)\n",
    "    processor = ConvNextImageProcessor.from_pretrained(model_path)\n",
    "    return model, processor\n",
    "\n",
    "def load_vgg(training_set_name:str):\n",
    "    vgg = timm.create_model('vgg16.tv_in1k', pretrained=True, num_classes=2)\n",
    "    data_config = timm.data.resolve_model_data_config(vgg)\n",
    "    vggcfg = VggConfig()\n",
    "    model = myvgg16(vgg, vggcfg)\n",
    "    model.load_state_dict(torch.load(VGG_PATH / training_set_name / 'pytorch_model.bin', map_location=torch.device('cpu')))\n",
    "    transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "    return model, transforms\n",
    "\n",
    "def load_inception(training_set_name:str):\n",
    "    vgg = timm.create_model('inception_v3.tv_in1k', pretrained=True, num_classes=2)\n",
    "    data_config = timm.data.resolve_model_data_config(vgg)\n",
    "    vggcfg = VggConfig()\n",
    "    model = myvgg16(vgg, vggcfg)\n",
    "    model.load_state_dict(torch.load(INCEPTION_PATH / training_set_name / 'pytorch_model.bin', map_location=torch.device('cpu')))\n",
    "    transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "    return model, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_vit(image_paths, model, processor, crop=False, mask=False):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n",
    "        if crop or mask:\n",
    "            mask_img = cv2.imread(str(MASKS_PATH / img_path.with_suffix('.png').name), 0)\n",
    "            if mask_img is None:\n",
    "                print(f'ViT: mask not found for {img_path.name}... skipping')\n",
    "                continue\n",
    "            masked_img = cv2.bitwise_and(img, img, mask=mask_img)\n",
    "            rows, cols = np.where(mask_img>0)\n",
    "            img = masked_img if mask else img\n",
    "            img = img[min(rows):max(rows), min(cols):max(cols)]\n",
    "        images.append(img)\n",
    "    start = time.time()\n",
    "    inputs = processor(images=images, return_tensors=\"pt\") # pt = torch.tensor\n",
    "    logits = model(**inputs).logits\n",
    "    print(f\"ViT avg time = {(time.time()-start)/len(image_paths)}s\")\n",
    "    return [model.config.id2label[lgt.argmax(-1).item()] for lgt in logits]\n",
    "\n",
    "def process_images_resnet(image_paths, model, processor, crop=False, mask=False):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n",
    "        if crop or mask:\n",
    "            mask_img = cv2.imread(str(MASKS_PATH / img_path.with_suffix('.png').name), 0)\n",
    "            if mask_img is None:\n",
    "                print(f'Resnet50: mask not found for {img_path.name}... skipping')\n",
    "                continue\n",
    "            masked_img = cv2.bitwise_and(img, img, mask=mask_img)\n",
    "            rows, cols = np.where(mask_img>0)\n",
    "            img = masked_img if mask else img\n",
    "            img = img[min(rows):max(rows), min(cols):max(cols)]\n",
    "        images.append(img)\n",
    "    start = time.time()\n",
    "    inputs = processor(images=images, return_tensors=\"pt\") # pt = torch.tensor\n",
    "    logits = model(**inputs).logits\n",
    "    print(f\"Resnet50 avg time = {(time.time()-start)/len(image_paths)}s\")\n",
    "    return [model.config.id2label[lgt.argmax(-1).item()] for lgt in logits]\n",
    "\n",
    "def process_images_vgg(image_paths, model, transforms, crop=False, mask=False):\n",
    "    results = []\n",
    "    times = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n",
    "        if crop or mask:\n",
    "            mask_img = cv2.imread(str(MASKS_PATH / img_path.with_suffix('.png').name), 0)\n",
    "            if mask_img is None:\n",
    "                print(f'VGG: mask not found for {img_path.name}... skipping')\n",
    "                continue\n",
    "            masked_img = cv2.bitwise_and(img, img, mask=mask_img)\n",
    "            rows, cols = np.where(mask_img>0)\n",
    "            img = masked_img if mask else img\n",
    "            img = img[min(rows):max(rows), min(cols):max(cols)]\n",
    "        start = time.time()\n",
    "        input_data = transforms(Image.fromarray(img)).unsqueeze(0)\n",
    "        prediction = model.model(input_data)\n",
    "        times.append(time.time()-start)\n",
    "        results.append(prediction)\n",
    "    print(f\"VGG avg time = {np.mean(times)}s\")\n",
    "    return [ID2LABEL[lgt.argmax(-1).item()] for lgt in results]\n",
    "\n",
    "def process_images_inception(image_paths, model, transforms, crop=False, mask=False):\n",
    "    results = []\n",
    "    times = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n",
    "        if crop or mask:\n",
    "            mask_img = cv2.imread(str(MASKS_PATH / img_path.with_suffix('.png').name), 0)\n",
    "            if mask_img is None:\n",
    "                print(f'InceptionV3: mask not found for {img_path.name}... skipping')\n",
    "                continue\n",
    "            masked_img = cv2.bitwise_and(img, img, mask=mask_img)\n",
    "            rows, cols = np.where(mask_img>0)\n",
    "            img = masked_img if mask else img\n",
    "            img = img[min(rows):max(rows), min(cols):max(cols)]\n",
    "        start = time.time()\n",
    "        input_data = transforms(Image.fromarray(img)).unsqueeze(0)\n",
    "        prediction = model.model(input_data)\n",
    "        times.append(time.time()-start)\n",
    "        results.append(prediction)\n",
    "    print(f\"InceptionV3 avg time = {np.mean(times)}s\")\n",
    "    return [ID2LABEL[lgt.argmax(-1).item()] for lgt in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## IMAGEM COMPLETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMAGEM COMPLETA === #\n",
    "DATASET = 'UNIFESP360'\n",
    "vit_model, vit_processor = load_vit(DATASET)\n",
    "resnet_model, resnet_processor = load_resnet(DATASET)\n",
    "vgg_model, vgg_transforms = load_vgg(DATASET)\n",
    "inception_model, inception_transforms = load_inception(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT avg time = 0.29108532269795734s\n",
      "Resnet50 avg time = 0.3042195638020833s\n",
      "VGG avg time = 0.21370326148139107s\n",
      "InceptionV3 avg time = 0.1442345513237847s\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f1.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f2.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f3.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f4.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f5.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f6.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f7.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f8.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f9.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT</th>\n",
       "      <th>Resnet50</th>\n",
       "      <th>Vgg16</th>\n",
       "      <th>InceptionV3</th>\n",
       "      <th>Ground Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f9</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ViT Resnet50    Vgg16 InceptionV3 Ground Truth\n",
       "f1  sem_dor  sem_dor  com_dor     com_dor      com_dor\n",
       "f2  sem_dor  sem_dor  sem_dor     sem_dor      sem_dor\n",
       "f3  com_dor  com_dor  com_dor     sem_dor      com_dor\n",
       "f4  com_dor  com_dor  com_dor     sem_dor      com_dor\n",
       "f5  com_dor  com_dor  sem_dor     sem_dor      com_dor\n",
       "f6  sem_dor  sem_dor  com_dor     sem_dor      sem_dor\n",
       "f7  com_dor  com_dor  com_dor     sem_dor      com_dor\n",
       "f8  com_dor  com_dor  com_dor     sem_dor      sem_dor\n",
       "f9  com_dor  com_dor  com_dor     sem_dor      sem_dor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions:\n",
      "- ViT: 66.67%\n",
      "- Resnet50: 66.67%\n",
      "- Vgg16: 55.56%\n",
      "- InceptionV3: 55.56%\n"
     ]
    }
   ],
   "source": [
    "vit_predictions = process_images_vit(img_files, vit_model, vit_processor, crop=False, mask=False)\n",
    "resnet_predictions = process_images_resnet(img_files, vit_model, vit_processor, crop=False, mask=False)\n",
    "vgg_predictions = process_images_vgg(img_files, vgg_model, vgg_transforms, crop=False, mask=False)\n",
    "inception_predictions = process_images_inception(img_files, inception_model, inception_transforms, crop=False, mask=False)\n",
    "\n",
    "cols = {'ViT': [], 'Resnet50': [], 'Vgg16': [], 'InceptionV3': [], 'Ground Truth': []}\n",
    "index = []\n",
    "for f, vit_pred, resnet_pred, vgg_pred, inception_pred in zip(img_files, vit_predictions, resnet_predictions, vgg_predictions, inception_predictions):\n",
    "    index.append(f.stem)\n",
    "    cols['ViT'].append(vit_pred)\n",
    "    cols['Resnet50'].append(resnet_pred)\n",
    "    cols['Vgg16'].append(vgg_pred)\n",
    "    cols['InceptionV3'].append(inception_pred)\n",
    "    cols['Ground Truth'].append(gt[f.stem])\n",
    "    print(f)\n",
    "\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "display(df)\n",
    "acc = lambda df, col: (df[col] == df['Ground Truth']).sum()/len(df)*100\n",
    "print(f\"Correct predictions:\\n- ViT: {acc(df,'ViT'):.2f}%\\n- Resnet50: {acc(df,'Resnet50'):.2f}%\\n- Vgg16: {acc(df,'Vgg16'):.2f}%\\n- InceptionV3: {acc(df,'InceptionV3'):.2f}%\")\n",
    "\n",
    "accuracies['ViT'].append(acc(df,'ViT'))\n",
    "accuracies['Resnet50'].append(acc(df,'Resnet50'))\n",
    "accuracies['Vgg16'].append(acc(df,'Vgg16'))\n",
    "accuracies['InceptionV3'].append(acc(df,'InceptionV3'))\n",
    "accuracies_index.append('Imagem Completa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## IMAGEM DA FACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMAGEM COMPLETA === #\n",
    "DATASET = 'UNIFESP360Faces'\n",
    "vit_model, vit_processor = load_vit(DATASET)\n",
    "resnet_model, resnet_processor = load_resnet(DATASET)\n",
    "vgg_model, vgg_transforms = load_vgg(DATASET)\n",
    "inception_model, inception_transforms = load_inception(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT avg time = 0.26304962899949813s\n",
      "Resnet50 avg time = 0.2758337656656901s\n",
      "VGG avg time = 0.20919283231099448s\n",
      "InceptionV3 avg time = 0.11867854330274794s\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f1.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f2.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f3.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f4.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f5.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f6.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f7.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f8.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f9.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT</th>\n",
       "      <th>Resnet50</th>\n",
       "      <th>Vgg16</th>\n",
       "      <th>InceptionV3</th>\n",
       "      <th>Ground Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f9</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ViT Resnet50    Vgg16 InceptionV3 Ground Truth\n",
       "f1  com_dor  com_dor  sem_dor     com_dor      com_dor\n",
       "f2  sem_dor  sem_dor  sem_dor     com_dor      sem_dor\n",
       "f3  com_dor  com_dor  com_dor     com_dor      com_dor\n",
       "f4  com_dor  com_dor  sem_dor     com_dor      com_dor\n",
       "f5  sem_dor  sem_dor  com_dor     com_dor      com_dor\n",
       "f6  com_dor  com_dor  sem_dor     com_dor      sem_dor\n",
       "f7  com_dor  com_dor  sem_dor     com_dor      com_dor\n",
       "f8  com_dor  com_dor  com_dor     com_dor      sem_dor\n",
       "f9  com_dor  com_dor  com_dor     com_dor      sem_dor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions:\n",
      "- ViT: 55.56%\n",
      "- Resnet50: 55.56%\n",
      "- Vgg16: 44.44%\n",
      "- InceptionV3: 55.56%\n"
     ]
    }
   ],
   "source": [
    "vit_predictions = process_images_vit(img_files, vit_model, vit_processor, crop=True, mask=False)\n",
    "resnet_predictions = process_images_resnet(img_files, vit_model, vit_processor, crop=True, mask=False)\n",
    "vgg_predictions = process_images_vgg(img_files, vgg_model, vgg_transforms, crop=True, mask=False)\n",
    "inception_predictions = process_images_inception(img_files, inception_model, inception_transforms, crop=True, mask=False)\n",
    "\n",
    "cols = {'ViT': [], 'Resnet50': [], 'Vgg16': [], 'InceptionV3': [], 'Ground Truth': []}\n",
    "index = []\n",
    "for f, vit_pred, resnet_pred, vgg_pred, inception_pred in zip(img_files, vit_predictions, resnet_predictions, vgg_predictions, inception_predictions):\n",
    "    index.append(f.stem)\n",
    "    cols['ViT'].append(vit_pred)\n",
    "    cols['Resnet50'].append(resnet_pred)\n",
    "    cols['Vgg16'].append(vgg_pred)\n",
    "    cols['InceptionV3'].append(inception_pred)\n",
    "    cols['Ground Truth'].append(gt[f.stem])\n",
    "    print(f)\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "display(df)\n",
    "acc = lambda df, col: (df[col] == df['Ground Truth']).sum()/len(df)*100\n",
    "print(f\"Correct predictions:\\n- ViT: {acc(df,'ViT'):.2f}%\\n- Resnet50: {acc(df,'Resnet50'):.2f}%\\n- Vgg16: {acc(df,'Vgg16'):.2f}%\\n- InceptionV3: {acc(df,'InceptionV3'):.2f}%\")\n",
    "\n",
    "accuracies['ViT'].append(acc(df,'ViT'))\n",
    "accuracies['Resnet50'].append(acc(df,'Resnet50'))\n",
    "accuracies['Vgg16'].append(acc(df,'Vgg16'))\n",
    "accuracies['InceptionV3'].append(acc(df,'InceptionV3'))\n",
    "accuracies_index.append('Face')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## IMAGEM DA FACE C/ MASCARA APLICADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMAGEM COMPLETA === #\n",
    "DATASET = 'UNIFESP360FacesMasked'\n",
    "vit_model, vit_processor = load_vit(DATASET)\n",
    "resnet_model, resnet_processor = load_resnet(DATASET)\n",
    "vgg_model, vgg_transforms = load_vgg(DATASET)\n",
    "inception_model, inception_transforms = load_inception(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT avg time = 0.26592792405022514s\n",
      "Resnet50 avg time = 0.28234680493672687s\n",
      "VGG avg time = 0.20776237381829155s\n",
      "InceptionV3 avg time = 0.1143656571706136s\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f1.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f2.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f3.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f4.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f5.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f6.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f7.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f8.jpg\n",
      "D:\\ComputerScience\\Mestrado\\data\\datasets\\Occlusion\\images\\f9.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT</th>\n",
       "      <th>Resnet50</th>\n",
       "      <th>Vgg16</th>\n",
       "      <th>InceptionV3</th>\n",
       "      <th>Ground Truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>sem_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f9</th>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>com_dor</td>\n",
       "      <td>sem_dor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ViT Resnet50    Vgg16 InceptionV3 Ground Truth\n",
       "f1  com_dor  com_dor  com_dor     com_dor      com_dor\n",
       "f2  sem_dor  sem_dor  com_dor     com_dor      sem_dor\n",
       "f3  com_dor  com_dor  com_dor     com_dor      com_dor\n",
       "f4  com_dor  com_dor  com_dor     com_dor      com_dor\n",
       "f5  com_dor  com_dor  com_dor     com_dor      com_dor\n",
       "f6  com_dor  com_dor  sem_dor     com_dor      sem_dor\n",
       "f7  com_dor  com_dor  com_dor     com_dor      com_dor\n",
       "f8  com_dor  com_dor  com_dor     com_dor      sem_dor\n",
       "f9  com_dor  com_dor  com_dor     com_dor      sem_dor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions:\n",
      "- ViT: 66.67%\n",
      "- Resnet50: 66.67%\n",
      "- Vgg16: 66.67%\n",
      "- InceptionV3: 55.56%\n"
     ]
    }
   ],
   "source": [
    "vit_predictions = process_images_vit(img_files, vit_model, vit_processor, crop=True, mask=True)\n",
    "resnet_predictions = process_images_resnet(img_files, vit_model, vit_processor, crop=True, mask=True)\n",
    "vgg_predictions = process_images_vgg(img_files, vgg_model, vgg_transforms, crop=True, mask=True)\n",
    "inception_predictions = process_images_inception(img_files, inception_model, inception_transforms, crop=True, mask=True)\n",
    "\n",
    "cols = {'ViT': [], 'Resnet50': [], 'Vgg16': [], 'InceptionV3': [], 'Ground Truth': []}\n",
    "index = []\n",
    "for f, vit_pred, resnet_pred, vgg_pred, inception_pred in zip(img_files, vit_predictions, resnet_predictions, vgg_predictions, inception_predictions):\n",
    "    index.append(f.stem)\n",
    "    cols['ViT'].append(vit_pred)\n",
    "    cols['Resnet50'].append(resnet_pred)\n",
    "    cols['Vgg16'].append(vgg_pred)\n",
    "    cols['InceptionV3'].append(inception_pred)\n",
    "    cols['Ground Truth'].append(gt[f.stem])\n",
    "    print(f)\n",
    "\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "display(df)\n",
    "acc = lambda df, col: (df[col] == df['Ground Truth']).sum()/len(df)*100\n",
    "print(f\"Correct predictions:\\n- ViT: {acc(df,'ViT'):.2f}%\\n- Resnet50: {acc(df,'Resnet50'):.2f}%\\n- Vgg16: {acc(df,'Vgg16'):.2f}%\\n- InceptionV3: {acc(df,'InceptionV3'):.2f}%\")\n",
    "\n",
    "accuracies['ViT'].append(acc(df,'ViT'))\n",
    "accuracies['Resnet50'].append(acc(df,'Resnet50'))\n",
    "accuracies['Vgg16'].append(acc(df,'Vgg16'))\n",
    "accuracies['InceptionV3'].append(acc(df,'InceptionV3'))\n",
    "accuracies_index.append('Face+Mascara')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ViT</th>\n",
       "      <th>Resnet50</th>\n",
       "      <th>Vgg16</th>\n",
       "      <th>InceptionV3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Imagem Completa</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>55.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Face</th>\n",
       "      <td>55.555556</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>55.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Face+Mascara</th>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>55.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ViT   Resnet50      Vgg16  InceptionV3\n",
       "Imagem Completa  66.666667  66.666667  55.555556    55.555556\n",
       "Face             55.555556  55.555556  44.444444    55.555556\n",
       "Face+Mascara     66.666667  66.666667  66.666667    55.555556"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(accuracies, index=accuracies_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "occ-gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
